nohup: ignoring input
Namespace(batch_size=128, checkpoint='', descriptor='SuperPoint+Boost-B', eval_interval=5, expand_piexl=5, lr=0.001, multiprocessing_context='spawn', num_epochs=100, num_workers=4, print_interval=5, random_seed=0, save_interval=10, save_path='work_dirs/SuperPoint+Boost-B_25_best_model_weights_scratch_decay.pth', test=False, test_image='', test_threshold=None, test_threshold_mul=1, train_ratio=0.25, warmup_step=20)
>>> device: cuda!
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, LinearLR, MultiStepLR, ChainedScheduler
from extract_features import normalize_keypoints, extractor_build, extract_img_feature
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, precision_recall_curve
from FeatureBooster.featurebooster import FeatureBooster, MLP
from mmengine.analysis import get_model_complexity_info
from torch.utils.data import DataLoader, Dataset
from torch.nn.utils.rnn import pad_sequence
from torch.nn.utils import clip_grad_norm_
from mmdet.models.losses import FocalLoss
from mmengine.dataset import Compose
from sklearn.cluster import DBSCAN
import multiprocessing as mp
from os import path as osp
from pathlib import Path
from torch import nn
import numpy as np
import matplotlib
matplotlib.use('Agg')  # 设置Agg为后端
import matplotlib.pyplot as plt
import warnings
import argparse
import shutil
import hashlib
import random
import torch
import time
import glob
import yaml
import cv2
import os
warnings.filterwarnings('ignore')

def parse_arguments():
    parser = argparse.ArgumentParser(description="Extract feature and refine descriptor using neural network to find ship keypoint.")
    
    parser.add_argument(
        '--descriptor', type=str, default='SuperPoint+Boost-B',
        help='descriptor to extract' )
    
    parser.add_argument(
        '--num_epochs', type=int, default=100,)
    
    parser.add_argument(
        '--train_ratio', type=float, default=1.0,
        help='The ratio of data used for training out of the training set' )    

    parser.add_argument(
        '--batch_size', type=int, default=256,)
    
    parser.add_argument(
        '--num_workers', type=int, default=16,)

    parser.add_argument(
        '--print_interval', type=int, default=5,)

    parser.add_argument(
        '--eval_interval', type=int, default=5,)
    
    parser.add_argument(
        '--save_interval', type=int, default=10,)

    parser.add_argument(
        '--lr', type=float, default=1e-3,)

    parser.add_argument(
        '--warmup_step', type=int, default=20,)

    parser.add_argument(
        '--random_seed', type=int, default=0,)

    parser.add_argument(
        '--expand_piexl', type=int, default=5,)

    parser.add_argument(
        '--test_threshold_mul', type=float, default=1,)
    
    parser.add_argument(
        '--test_threshold', type=float, default=None,)
           
    parser.add_argument(
        '--test_image', type=str, default='' ,)
    
    parser.add_argument(
        '--test', action='store_true',)
    
    parser.add_argument(
        '--save_path', type=str, default='',)
    
    parser.add_argument(
        '--checkpoint', type=str, default='',)

    parser.add_argument(
        '--multiprocessing_context', type=str, default=None,)
        
    args = parser.parse_args()
    return args

def calculate_md5(file_path):
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        # 以块的方式读取文件，以防文件太大
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

# 定义舰船目标关键点检测模型（示例）
class ShipKeyPointsModel(nn.Module):
    def __init__(self, descriptor, device='cpu', pretrained =''):
        super().__init__() 
        self.device = device       
        # load json config file
        config_file = Path(__file__).parent / "config.yaml"
        with open(str(config_file), 'r') as f:
            config = yaml.load(f, Loader=yaml.FullLoader)
        self.config = config[descriptor]
        self.k = nn.Parameter(torch.tensor(1.0))
        # Model
        self.feature_booster = FeatureBooster(self.config)
        # load the model
        if os.path.isfile(pretrained):
            self.feature_booster.load_state_dict(torch.load(pretrained))
            print(f">>> feature_booster weights loaded from {pretrained}!")
        self.fc_out = MLP([self.config['output_dim'], self.config['output_dim']//2,1])
        self.fc_thed = MLP([self.config['output_dim'], self.config['output_dim']//2,1])
        self.to(self.device)
        
    def forward(self, x):
        x = self.feature_booster(x[...,self.config['keypoint_dim']:], x[...,:self.config['keypoint_dim']])
        x = (self.fc_out(x)-self.fc_thed(torch.mean(x,dim=-2,keepdim=True))).squeeze(-1)
        return torch.sigmoid(self.k* x)
    
# 定义数据集（示例）
class ShipKeyPointsDataset(Dataset):
    def __init__(self, data_root, descriptor, expand_piexl = 5, pipeline = [], img_suffix = 'png', debug = False, device = torch.device('cpu'), **kwargs):
        super(ShipKeyPointsDataset, self).__init__()
        self.transform = Compose(pipeline)  
        self.expand_piexl = expand_piexl
        self.debug = debug
        self.img_suffix = img_suffix
        self.descriptor = descriptor
        self.device = device
        config_file = Path(__file__).parent / "config.yaml"
        with open(str(config_file), 'r') as f:
            config = yaml.load(f, Loader=yaml.FullLoader)
        self.config = config[descriptor]
        self.extractor = extractor_build(self.descriptor, device = self.device)
        if 'ann_file' in kwargs and kwargs['ann_file'] !='': 
            # train case  
            ann_dir = kwargs['ann_file']
            if isinstance(ann_dir, str):
                ann_dir = [ann_dir]
        else:
            ann_dir = []
        self.txt_files = []
        for path in ann_dir:
            self.txt_files.extend(glob.glob(osp.join(data_root, path, "**/*.txt"), recursive=True))

        if 'train_ratio' in kwargs:
            self.txt_files = random.sample(self.txt_files, int(np.ceil(len(self.txt_files)*kwargs['train_ratio'])))

    def __len__(self):
        return len(self.txt_files)

    def load_data_info(self, idx):
        data_info = {}
        txt_file = self.txt_files[idx]
        img_id = osp.split(txt_file)[1][:-4]
        data_info['img_id'] = img_id
        img_name = img_id + f'.{self.img_suffix}'
        data_info['file_name'] = img_name
        
        img_path = txt_file.replace('.txt','.png').replace('labelTxt','images')
        data_info['img_path'] = img_path
        
        instances = []
        with open(txt_file) as f:
            s = f.readlines()
            for si in s:
                instance = {}
                bbox_info = si.split()
                instance['bbox_label'] = 0                       
                instance['ignore_flag'] = 0
                instance['bbox'] = [float(i) for i in bbox_info[:8]]
                instances.append(instance)
        data_info['instances'] = instances
        return data_info
                
    def __getitem__(self, idx):
        data_info = self.load_data_info(idx)
        bboxes = []
        if len(self.transform.transforms):       
            data = self.transform(data_info)
            image = data['inputs'].cpu().numpy().transpose(1, 2, 0)
            box = data['data_samples'].gt_instances.bboxes.tensor
            for box_id in range(box.shape[0]):
                instances = box[box_id]
                bboxes.append(np.array([(instances[i], instances[i + 1]) for i in range(0, len(instances), 2)], dtype=np.int32)) 
            del data
        else:
            image = cv2.cvtColor(cv2.imread(data_info['img_path']), cv2.COLOR_BGR2RGB)
            for instances in data_info['instances']:
               bboxes.append(np.array([(instances['bbox'][i], instances['bbox'][i + 1]) for i in range(0, len(instances['bbox']), 2)], dtype=np.int32)) 
        keypoints, descriptors, image = extract_img_feature(self.descriptor, image, self.extractor)    
        if len(keypoints) <= 0:
            print(f">>> {data_info['img_path']} has no keypoint founded with {self.descriptor}")
            return torch.zeros([2, self.config['keypoint_dim'] + self.config['descriptor_dim'] + 2], dtype = torch.float32, requires_grad = False), data_info['img_path']
        else:     
            tmp = np.zeros(image.shape[:2], dtype=np.uint8)
            if len(bboxes) > 0 :
                cv2.fillPoly(tmp, bboxes, 1)
            target = np.array([np.any(tmp[max(0,int(kp[1]-self.expand_piexl)):min(int(kp[1]+self.expand_piexl),image.shape[0]),
                                        max(0,int(kp[0]-self.expand_piexl)):min(int(kp[0]+self.expand_piexl),image.shape[1])]) 
                            for kp in keypoints ]) 
            # visualization
            if self.debug:
                print(f">>> VISUALIZATION: {data_info['img_path']}")
                kps = np.array([cv2.KeyPoint(*kp) for kp in keypoints])
                image = cv2.drawKeypoints(image, kps[target], None, color=(255,0,0,)) 
                image = cv2.drawKeypoints(image, kps[~target], None, color=(0,0,255)) 
                image = cv2.polylines(image, bboxes, isClosed=True, color=(0, 255, 0), thickness=2)
                cv2.imwrite('test_2.jpg', cv2.cvtColor(image, cv2.COLOR_RGB2BGR)) 

            # boosted the descriptor using trained model
            keypoints = normalize_keypoints(keypoints, image.shape).astype(np.float32)
            if 'orb' in self.descriptor.lower():
                descriptors = np.unpackbits(descriptors, axis=1, bitorder='little').astype(np.float32)
                descriptors = descriptors * 2.0 - 1.0
            # 最后的全一是为了区分对齐batch的padding数据              
            result = torch.from_numpy(np.concatenate([keypoints, descriptors, target.reshape(-1, 1), np.ones([len(target),1])], axis=-1))  
            result.requires_grad = False                 
            return result, data_info['img_path']

def get_metric(all_labels, all_output, all_thred):
    
    if isinstance(all_output, torch.Tensor):
        if all_output.requires_grad:
            all_output = all_output.detach()
        all_output = all_output.cpu().numpy()    
    if isinstance(all_labels, torch.Tensor):
        all_labels = all_labels.cpu().numpy()
    if isinstance(all_thred, torch.Tensor):
        all_thred = all_thred.cpu().numpy()
        
    all_predict = (all_output>all_thred) 
    all_labels = all_labels   
    all_output = all_output        
    accuracy = accuracy_score(all_labels, all_predict)
    precision = precision_score(all_labels, all_predict)
    recall = recall_score(all_labels, all_predict)
    F1_score = f1_score(all_labels, all_predict)
    AP_score = average_precision_score(all_labels, all_output)
    metric_dict = dict(Accuracy=accuracy, Precision=precision, Recall=recall, F1_score=F1_score, Average_Precision = AP_score)
    metric_str = "Accuracy: {Accuracy:.2f}、Precision: {Precision:.2f}、Recall: {Recall:.2f}、F1-score: {F1_score:.2f}、Average_Precision: {Average_Precision:.2f}".format(**metric_dict)
    print(metric_str)
    precisions, recalls, _ = precision_recall_curve(all_labels, all_output)
    PR_dict = dict(Precision=precisions, Recall=recalls)
    return metric_dict, PR_dict

def test(model, args): 
    model.eval()
    device = model.device
    extractor = extractor_build(args.descriptor)
    keypoints, descriptors, image = extract_img_feature(args.descriptor, cv2.cvtColor(cv2.imread(args.test_image), cv2.COLOR_BGR2RGB), extractor)
            
    boxes = []
    with open(args.test_image.replace('.png','.txt').replace('images','labelTxt'), 'r') as file:
        for line in file:
            coordinates = [float(coord) for coord in line.strip().split()[:8]]
            boxes.append(np.array([(coordinates[i], coordinates[i + 1]) for i in range(0, len(coordinates), 2)], dtype=np.int32))
    tmp = np.zeros(image.shape[:2], dtype=np.uint8)
    if len(boxes) > 0 :
        cv2.fillPoly(tmp, boxes, 1) 
    labels = np.array([np.any(tmp[max(0,int(kp[1]-args.expand_piexl)):min(int(kp[1]+args.expand_piexl),image.shape[0]),
                                max(0,int(kp[0]-args.expand_piexl)):min(int(kp[0]+args.expand_piexl),image.shape[1])]) 
                    for kp in keypoints ]) 
    
    kps = np.array([cv2.KeyPoint(*kp) for kp in keypoints])

    # boosted the descriptor using trained model
    keypoints = normalize_keypoints(keypoints, image.shape).astype(np.float32)
    if 'orb' in args.descriptor.lower():
        descriptors = np.unpackbits(descriptors, axis=1, bitorder='little').astype(np.float32)
        descriptors = descriptors * 2.0 - 1.0
    with torch.no_grad():                  
        output = model(torch.from_numpy(np.concatenate([keypoints, descriptors,], axis=-1)).to(device).float()).cpu().numpy()  
    if args.test_threshold is None:
        threshold, _  = cv2.threshold((output * 255).astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  
        threshold = min(threshold/255.0 * args.test_threshold_mul, 0.95) 
        print(f"Threshold is drived from OTSU algorithm :{threshold}.")   
    else:
        print(f"Threshold is a constant value {args.test_threshold}.") 
        threshold = args.test_threshold
    predict = (output > threshold)

    metric_dict, PR_dict = get_metric(labels, output, threshold)
    
    image = cv2.drawKeypoints(image, kps[predict], None, color=(0, 255, 0),) # 红色 虚警 
    # image = cv2.drawKeypoints(image, kps[(~predict)&(labels)], None, color=(0,0,255)) # Aqua蓝色 漏检 
    # image = cv2.drawKeypoints(image, kps[predict&labels], None, color=(0,0,255,),) # 黄色 正确预测(正样本)
    # image = cv2.drawKeypoints(image, kps[(~predict)&(~labels)], None, color= (0, 255, 0) ) # 绿色 正确预测(负样本)
    # image = cv2.drawKeypoints(image, kps[(label)], None, color=(255,0,0,))
    # image = cv2.drawKeypoints(image, kps[(~label)], None, color=(0,0,255))
    image = cv2.polylines(image, boxes, isClosed=True, color=(255, 255, 0), thickness=2)
    cv2.imwrite('test.jpg', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  
    return metric_dict, PR_dict

def evaluate(model, data_root, ann_file, args):
    model.eval() 
    device = model.device
    eva_dataset = ShipKeyPointsDataset(data_root, args.descriptor, expand_piexl = args.expand_piexl, ann_file = ann_file, device = device)
    eva_loader = DataLoader(eva_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=custom_collate_fn,pin_memory=True,multiprocessing_context=args.multiprocessing_context)

    all_output = torch.tensor([], device=device)
    all_labels = torch.tensor([], device=device)
    all_thred = torch.tensor([], device=device)     
    if args.test_threshold is None:
        print(f"Threshold is drived from OTSU algorithm.")
    else:
        print(f"Threshold is a constant value {args.test_threshold}.") 
        all_thred = args.test_threshold
    
    with torch.no_grad():
        for i, (data, img_paths) in enumerate(eva_loader):
            data = data.to(device).float()  # 将测试数据移动到GPU
            outputs = model(data[:,:,:-2])
            
            if args.test_threshold is None:
                for k in range(outputs.shape[0]):
                    thred, _  = cv2.threshold((outputs[k] * 255).cpu().numpy().astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                    all_thred = torch.cat([all_thred, torch.tensor([min(thred/255.0 * args.test_threshold_mul, 0.95)]*(int(data[k,:,-1].sum())), device=device) ])            
                    
            all_output = torch.cat([all_output, outputs[data[:,:,-1].bool()]])    
            all_labels = torch.cat([all_labels, data[:,:,-2].bool()[data[:,:,-1].bool()]]) 

            if (i + 1) % args.print_interval == 0:
                print(f"{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) : [{i + 1}/{len(eva_loader)}]")

    return get_metric(all_labels, all_output, all_thred)
 

def train(model, args):
    device = model.device
    
    train_pipeline = [
        dict(type='mmdet.LoadImageFromFile', backend_args=None),
        dict(type='mmdet.LoadAnnotations', with_bbox=True, box_type='qbox'),
        dict(
            type='mmrotate.ConvertBoxType',
            box_type_mapping=dict(gt_bboxes='rbox')),
        dict(type='mmdet.RandomCrop', crop_size=(800,800)),
        dict(
            type='mmrotate.RandomRotate',
            prob=0.5,
            angle_range=180,
            rotate_type='mmrotate.Rotate'),
        dict(
            type='mmdet.RandomFlip',
            prob=0.75,
            direction=['horizontal', 'vertical', 'diagonal']),
        dict(
            type='mmdet.RandomAffine',),    
        dict(
            type='mmdet.PhotoMetricDistortion',),    

        dict(
            type='mmrotate.ConvertBoxType',
            box_type_mapping=dict(gt_bboxes='qbox')),
        dict(type='mmdet.PackDetInputs', meta_keys=())]
    train_pipeline = [] 
    train_dataset = ShipKeyPointsDataset("data/hrsid/", args.descriptor, expand_piexl = args.expand_piexl, ann_file = ['trainsplit/','valplit/'], pipeline = train_pipeline, device = device, train_ratio = args.train_ratio)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=custom_collate_fn, worker_init_fn=worker_init_fn,pin_memory=True,multiprocessing_context=args.multiprocessing_context)
    
    outputs = get_model_complexity_info(
        model,
        input_shape=None,
        inputs=train_dataset.__getitem__(0)[0][:,:-2].float().to(device),  # the input tensor of the model
        show_table=True,  # show the complexity table
        show_arch=False)  # show the complexity arch
    for k, v in outputs.items():
        print(f"{k}: {v}")
    
    # 定义损失函数和优化器
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)
    total_steps = len(train_loader) * args.num_epochs
    scheduler = ChainedScheduler([LinearLR(optimizer, start_factor=1.0 / 20, end_factor=1.0, total_iters=args.warmup_step, last_epoch=-1, verbose=False),
                                CosineAnnealingWarmRestarts(optimizer, T_0 = (total_steps - args.warmup_step)//8, T_mult=1, eta_min=5e-7, verbose=False)])
    
    start_epoch = 0
    best_AP = 0.0
    if len(args.checkpoint):
        checkpoint = torch.load(args.checkpoint)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict']),
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch']+1
        best_AP = checkpoint['best_AP']
        print(f'>>> Continue training from epoch [{start_epoch}] !')
    
    for epoch in range(start_epoch, args.num_epochs):       
        start_time = time.time()
        model.train()
        for i, (data, img_paths)  in enumerate(train_loader):
            optimizer.zero_grad()
            data = data.to(device).float()
            outputs = model(data[:,:,:-2])
            vaild = data[:,:,-1].reshape(-1).bool()
            loss = criterion(outputs.reshape(-1)[vaild], data[:,:,-2].reshape(-1)[vaild])
            loss.backward()

            clip_grad_norm_(model.parameters(), 35, 2)
            optimizer.step()
            scheduler.step()
            if (i + 1) % args.print_interval == 0:
                current_time = time.time()
                eta_seconds = (current_time - start_time) / (i+1) * ( (args.num_epochs - epoch ) * len(train_loader) - (i + 1))
                eta_str = str(int(eta_seconds // 3600)) + ':' + str(int((eta_seconds % 3600) // 60)) + ':' + str(int(eta_seconds % 60))
                print(f"{time.strftime('%m/%d %H:%M:%S')} - Epoch(train)  [{epoch + 1}/{args.num_epochs}][{i + 1}/{len(train_loader)}]  lr: {optimizer.param_groups[0]['lr']:.4e}  eta: {eta_str}  time: {current_time - start_time:.4f}   loss: {loss:.4f}")
            
        if ((epoch+1) % args.eval_interval == 0) or (epoch == 0) or (epoch == args.num_epochs-1):
            print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - all: [{epoch+1}/{args.num_epochs}]:") 
            metric_dict_all, _ = evaluate(model, "data/hrsid/", ['testsplit/all/'], args)
            
            # print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - offshore: [{epoch+1}/{args.num_epochs}]:")  
            # metric_dict, _ = evaluate(model, "data/hrsid/", ['testsplit/offshore/'], args)
              
            print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - inshore: [{epoch+1}/{args.num_epochs}]:") 
            _, _ = evaluate(model, "data/hrsid/", ['testsplit/inshore/'], args)
            
            # 检查是否有更好的模型，如果有，则保存权重
            if metric_dict_all['Average_Precision'] > best_AP:
                best_AP = metric_dict_all['Average_Precision']
                # 保存当前模型的权重
                torch.save(model.state_dict(), args.save_path)
                print(f"{time.strftime('%m/%d %H:%M:%S')} - Best model achieved at epoch {epoch + 1}, with all test image AP {best_AP:.4f}")
            if (epoch >= args.num_epochs-1):
                last_save_path = 'work_dirs/' + args.descriptor + '_last_model_weight.pth'
                torch.save(model.state_dict(), last_save_path)
                print(f"{time.strftime('%m/%d %H:%M:%S')} - Last model saved :{last_save_path}") 

        if ((epoch+1) % args.save_interval == 0):
            for file_path in glob.glob(args.save_path[:-4] + '*_epoch.pth'):
                os.remove(file_path)
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'best_AP': best_AP,
                }, args.save_path[:-4] + f'_{epoch+1}_epoch.pth') 
    
def worker_init_fn(worker_id):
    # torch.cuda.set_device(worker_id) 指定数加载设备
    torch.cuda.manual_seed_all(worker_id)   

def custom_collate_fn(batch):
    results = [item[0] for item in batch]  # 提取每个样本的result
    img_paths = [item[1] for item in batch]  # 提取每个样本的img_path
    padded_results = pad_sequence(results, batch_first=True, padding_value=0)
    return padded_results, img_paths
    
if __name__ == '__main__': 

    args = parse_arguments()

    random.seed(args.random_seed)
    np.random.seed(args.random_seed)
    torch.manual_seed(args.random_seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.random_seed)  

    if ('alike' in args.descriptor.lower()) or ('superpoint' in args.descriptor.lower()) or ('hardnet' in args.descriptor.lower()) or ('sosnet' in args.descriptor.lower()):
        args.multiprocessing_context = 'spawn'
        args.batch_size = 128
        args.num_workers = 4
        
    pretrained = '' # Path(__file__).parent / str("FeatureBooster/models/" + args.descriptor + ".pth")
    pretrained_str = 'finetune' if os.path.isfile(pretrained) else 'scratch'
    args.save_path = args.save_path if len(args.save_path) else 'work_dirs/' + args.descriptor + f'{args.train_ratio*100:.0f}_' + f'_best_model_weights_{pretrained_str}.pth'
    
    print(args)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") 
    print(f">>> device: {device}!")          
    model = ShipKeyPointsModel(args.descriptor, device=device, pretrained = pretrained)

    if not args.test:
        with open(__file__, 'r') as file:
            lines = file.readlines() 
        for line in lines:
            print(line[:-1])
        print('\n')   
        train(model, args)
        
    model.load_state_dict(torch.load(args.save_path), strict=False)
    model_weights_md5 = calculate_md5(args.save_path)
    print(f">>> model weights loaded from {args.save_path} with MD5 {model_weights_md5}!")

    if not len(args.test_image):        
        print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - all:") 
        metric_dict, PR_dict_all = evaluate(model, "data/hrsid/", ['testsplit/all/'], args)
            
        print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - offshore:")  
        metric_dict, PR_dict_offshore = evaluate(model, "data/hrsid/", ['testsplit/offshore/'], args)
            
        print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - inshore:") 
        metric_dict, PR_dict_inshore = evaluate(model, "data/hrsid/", ['testsplit/inshore/'], args)

        plt.figure()
        plt.plot(PR_dict_all['Recall'], PR_dict_all['Precision'], label='PR curve for all')
        plt.plot(PR_dict_offshore['Recall'], PR_dict_offshore['Precision'], label='PR curve for offshore')
        plt.plot(PR_dict_inshore['Recall'], PR_dict_inshore['Precision'], label='PR curve for inshore')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        # plt.title('Precision-Recall Curve')
        plt.legend()
        PR_curve_path = 'work_dirs/' + f'PR_curve_{args.save_path.split("/")[-1][:-4]}_{model_weights_md5[:5]}.png'
        plt.savefig(PR_curve_path, bbox_inches='tight', dpi=300)  
        print(f">>> PR_cruve saved: {PR_curve_path}")
        
        shutil.copyfile(args.save_path,'/XrayDet/keypoint_results/')
        shutil.copyfile(PR_curve_path,'/XrayDet/keypoint_results/')
    else:
        print(f"\n{time.strftime('%m/%d %H:%M:%S')} - Epoch(test) - {args.test_image}:")            
        metric_dict, PR_dict = test(model, args


11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::add encountered 2 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::sigmoid encountered 10 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::softmax encountered 9 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::mul encountered 19 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::sum encountered 9 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::add_ encountered 18 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::tanh encountered 1 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::mean encountered 1 time(s)
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::sub encountered 1 time(s)
11/08 01:47:09 - mmengine - WARNING - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
feature_booster.attn_proj.layers.0.attn.dropout, feature_booster.attn_proj.layers.0.ffn.dropout, feature_booster.attn_proj.layers.1.attn.dropout, feature_booster.attn_proj.layers.1.ffn.dropout, feature_booster.attn_proj.layers.2.attn.dropout, feature_booster.attn_proj.layers.2.ffn.dropout, feature_booster.attn_proj.layers.3.attn.dropout, feature_booster.attn_proj.layers.3.ffn.dropout, feature_booster.attn_proj.layers.4.attn.dropout, feature_booster.attn_proj.layers.4.ffn.dropout, feature_booster.attn_proj.layers.5.attn.dropout, feature_booster.attn_proj.layers.5.ffn.dropout, feature_booster.attn_proj.layers.6.attn.dropout, feature_booster.attn_proj.layers.6.ffn.dropout, feature_booster.attn_proj.layers.7.attn.dropout, feature_booster.attn_proj.layers.7.ffn.dropout, feature_booster.attn_proj.layers.8.attn.dropout, feature_booster.attn_proj.layers.8.ffn.dropout, feature_booster.denc.dropout, feature_booster.dropout, feature_booster.kenc.dropout
11/08 01:47:09 - mmengine - WARNING - Unsupported operator aten::layer_norm encountered 19 time(s)
flops: 82378368
flops_str: 82.378M
activations: 288401
activations_str: 0.288M
params: 5183043
params_str: 5.183M
out_table: 
+---------------------------+----------------------+------------+--------------+
| module                    | #parameters or shape | #flops     | #activations |
+---------------------------+----------------------+------------+--------------+
| model                     | 5.183M               | 82.378M    | 0.288M       |
|  k                        |  ()                  |            |              |
|  feature_booster          |  5.117M              |  81.819M   |  0.286M      |
|   feature_booster.kenc.e… |   0.109M             |   1.738M   |   11.776K    |
|    feature_booster.kenc.… |    0.128K            |    1.536K  |    0.512K    |
|    feature_booster.kenc.… |    2.112K            |    32.768K |    1.024K    |
|    feature_booster.kenc.… |    8.32K             |    0.131M  |    2.048K    |
|    feature_booster.kenc.… |    33.024K           |    0.524M  |    4.096K    |
|    feature_booster.kenc.… |    65.792K           |    1.049M  |    4.096K    |
|   feature_booster.denc.e… |   0.197M             |   3.146M   |   12.288K    |
|    feature_booster.denc.… |    65.792K           |    1.049M  |    4.096K    |
|    feature_booster.denc.… |    65.792K           |    1.049M  |    4.096K    |
|    feature_booster.denc.… |    65.792K           |    1.049M  |    4.096K    |
|   feature_booster.attn_p… |   4.744M             |   75.866M  |   0.258M     |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|    feature_booster.attn_… |    0.527M            |    8.43M   |    28.672K   |
|   feature_booster.final_… |   65.792K            |   1.049M   |   4.096K     |
|    feature_booster.final… |    (256, 256)        |            |              |
|    feature_booster.final… |    (256,)            |            |              |
|   feature_booster.layer_… |   0.512K             |   20.48K   |   0          |
|    feature_booster.layer… |    (256,)            |            |              |
|    feature_booster.layer… |    (256,)            |            |              |
|  fc_out                   |  33.025K             |  0.526M    |  2.064K      |
|   fc_out.0                |   32.896K            |   0.524M   |   2.048K     |
|    fc_out.0.weight        |    (128, 256)        |            |              |
|    fc_out.0.bias          |    (128,)            |            |              |
|   fc_out.2                |   0.129K             |   2.048K   |   16         |
|    fc_out.2.weight        |    (1, 128)          |            |              |
|    fc_out.2.bias          |    (1,)              |            |              |
|  fc_thed                  |  33.025K             |  32.896K   |  0.129K      |
|   fc_thed.0               |   32.896K            |   32.768K  |   0.128K     |
|    fc_thed.0.weight       |    (128, 256)        |            |              |
|    fc_thed.0.bias         |    (128,)            |            |              |
|   fc_thed.2               |   0.129K             |   0.128K   |   1          |
|    fc_thed.2.weight       |    (1, 128)          |            |              |
|    fc_thed.2.bias         |    (1,)              |            |              |
+---------------------------+----------------------+------------+--------------+

out_arch: 
11/08 01:47:26 - Epoch(train)  [1/100][5/8]  lr: 9.9346e-04  eta: 0:44:11  time: 16.6792   loss: 0.4601

11/08 01:47:28 - Epoch(test) - all: [1/100]:
Threshold is drived from OTSU algorithm.
11/08 01:47:54 - Epoch(test) : [5/16]
11/08 01:48:00 - Epoch(test) : [10/16]
11/08 01:48:06 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.57

11/08 01:48:08 - Epoch(test) - inshore: [1/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.29
11/08 01:48:22 - Best model achieved at epoch 1, with all test image AP 0.5668
11/08 01:48:38 - Epoch(train)  [2/100][5/8]  lr: 9.5635e-04  eta: 0:40:29  time: 15.4365   loss: 0.4313
11/08 01:48:57 - Epoch(train)  [3/100][5/8]  lr: 8.8880e-04  eta: 0:42:10  time: 16.2450   loss: 0.4813
11/08 01:49:16 - Epoch(train)  [4/100][5/8]  lr: 7.9530e-04  eta: 0:42:39  time: 16.5959   loss: 0.3978
11/08 01:49:34 - Epoch(train)  [5/100][5/8]  lr: 6.8211e-04  eta: 0:39:21  time: 15.4735   loss: 0.4787

11/08 01:49:37 - Epoch(test) - all: [5/100]:
Threshold is drived from OTSU algorithm.
11/08 01:50:03 - Epoch(test) : [5/16]
11/08 01:50:11 - Epoch(test) : [10/16]
11/08 01:50:16 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.64

11/08 01:50:19 - Epoch(test) - inshore: [5/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.31
11/08 01:50:33 - Best model achieved at epoch 5, with all test image AP 0.6395
11/08 01:50:50 - Epoch(train)  [6/100][5/8]  lr: 5.5678e-04  eta: 0:40:54  time: 16.2574   loss: 0.4684
11/08 01:51:08 - Epoch(train)  [7/100][5/8]  lr: 4.2767e-04  eta: 0:39:31  time: 15.8753   loss: 0.3823
11/08 01:51:27 - Epoch(train)  [8/100][5/8]  lr: 3.0341e-04  eta: 0:38:56  time: 15.8055   loss: 0.3677
11/08 01:51:45 - Epoch(train)  [9/100][5/8]  lr: 1.9229e-04  eta: 0:38:16  time: 15.7078   loss: 0.3674
11/08 01:52:02 - Epoch(train)  [10/100][5/8]  lr: 1.0173e-04  eta: 0:37:12  time: 15.4414   loss: 0.3073

11/08 01:52:05 - Epoch(test) - all: [10/100]:
Threshold is drived from OTSU algorithm.
11/08 01:52:32 - Epoch(test) : [5/16]
11/08 01:52:39 - Epoch(test) : [10/16]
11/08 01:52:45 - Epoch(test) : [15/16]
Accuracy: 0.76、Precision: 0.42、Recall: 0.88、F1-score: 0.57、Average_Precision: 0.77

11/08 01:52:47 - Epoch(test) - inshore: [10/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.70、Precision: 0.26、Recall: 0.80、F1-score: 0.39、Average_Precision: 0.39
11/08 01:53:01 - Best model achieved at epoch 10, with all test image AP 0.7692
11/08 01:53:18 - Epoch(train)  [11/100][5/8]  lr: 3.7771e-05  eta: 0:38:36  time: 16.1960   loss: 0.2712
11/08 01:53:36 - Epoch(train)  [12/100][5/8]  lr: 4.6879e-06  eta: 0:36:30  time: 15.4945   loss: 0.2522
11/08 01:53:55 - Epoch(train)  [13/100][5/8]  lr: 9.9581e-04  eta: 0:37:37  time: 16.1492   loss: 0.4818
11/08 01:54:15 - Epoch(train)  [14/100][5/8]  lr: 9.6273e-04  eta: 0:39:40  time: 17.2253   loss: 0.4015
11/08 01:54:33 - Epoch(train)  [15/100][5/8]  lr: 8.9877e-04  eta: 0:35:30  time: 15.5975   loss: 0.4744

11/08 01:54:35 - Epoch(test) - all: [15/100]:
Threshold is drived from OTSU algorithm.
11/08 01:55:02 - Epoch(test) : [5/16]
11/08 01:55:09 - Epoch(test) : [10/16]
11/08 01:55:14 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.69

11/08 01:55:16 - Epoch(test) - inshore: [15/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.35
11/08 01:55:48 - Epoch(train)  [16/100][5/8]  lr: 8.0821e-04  eta: 0:38:18  time: 17.0268   loss: 0.4249
11/08 01:56:06 - Epoch(train)  [17/100][5/8]  lr: 6.9709e-04  eta: 0:35:18  time: 15.8777   loss: 0.4993
11/08 01:56:24 - Epoch(train)  [18/100][5/8]  lr: 5.7283e-04  eta: 0:35:17  time: 16.0694   loss: 0.4738
11/08 01:56:42 - Epoch(train)  [19/100][5/8]  lr: 4.4372e-04  eta: 0:34:15  time: 15.7854   loss: 0.4808
11/08 01:57:01 - Epoch(train)  [20/100][5/8]  lr: 3.1839e-04  eta: 0:35:12  time: 16.4247   loss: 0.4538

11/08 01:57:04 - Epoch(test) - all: [20/100]:
Threshold is drived from OTSU algorithm.
11/08 01:57:30 - Epoch(test) : [5/16]
11/08 01:57:36 - Epoch(test) : [10/16]
11/08 01:57:43 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.51

11/08 01:57:44 - Epoch(test) - inshore: [20/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.31
11/08 01:58:18 - Epoch(train)  [21/100][5/8]  lr: 2.0520e-04  eta: 0:34:11  time: 16.1574   loss: 0.4526
11/08 01:58:36 - Epoch(train)  [22/100][5/8]  lr: 1.1170e-04  eta: 0:32:11  time: 15.4025   loss: 0.4008
11/08 01:58:54 - Epoch(train)  [23/100][5/8]  lr: 4.4146e-05  eta: 0:30:53  time: 14.9730   loss: 0.4902
11/08 01:59:13 - Epoch(train)  [24/100][5/8]  lr: 7.0384e-06  eta: 0:31:51  time: 15.6437   loss: 0.4575
11/08 01:59:31 - Epoch(train)  [25/100][5/8]  lr: 9.9764e-04  eta: 0:30:35  time: 15.2175   loss: 0.4839

11/08 01:59:34 - Epoch(test) - all: [25/100]:
Threshold is drived from OTSU algorithm.
11/08 02:00:00 - Epoch(test) : [5/16]
11/08 02:00:07 - Epoch(test) : [10/16]
11/08 02:00:13 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.49

11/08 02:00:15 - Epoch(test) - inshore: [25/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.30
11/08 02:00:44 - Epoch(train)  [26/100][5/8]  lr: 9.6862e-04  eta: 0:31:57  time: 16.1124   loss: 0.5193
11/08 02:01:02 - Epoch(train)  [27/100][5/8]  lr: 9.0833e-04  eta: 0:29:24  time: 15.0318   loss: 0.5033
11/08 02:01:21 - Epoch(train)  [28/100][5/8]  lr: 8.2079e-04  eta: 0:30:35  time: 15.8548   loss: 0.4393
11/08 02:01:38 - Epoch(train)  [29/100][5/8]  lr: 7.1186e-04  eta: 0:28:43  time: 15.0960   loss: 0.5235
11/08 02:01:57 - Epoch(train)  [30/100][5/8]  lr: 5.8880e-04  eta: 0:29:40  time: 15.8103   loss: 0.3358

11/08 02:01:59 - Epoch(test) - all: [30/100]:
Threshold is drived from OTSU algorithm.
11/08 02:02:25 - Epoch(test) : [5/16]
11/08 02:02:32 - Epoch(test) : [10/16]
11/08 02:02:38 - Epoch(test) : [15/16]
Accuracy: 0.58、Precision: 0.28、Recall: 0.82、F1-score: 0.41、Average_Precision: 0.69

11/08 02:02:40 - Epoch(test) - inshore: [30/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.64、Precision: 0.20、Recall: 0.67、F1-score: 0.31、Average_Precision: 0.33
11/08 02:03:11 - Epoch(train)  [31/100][5/8]  lr: 4.5983e-04  eta: 0:28:56  time: 15.6447   loss: 0.2488
11/08 02:03:29 - Epoch(train)  [32/100][5/8]  lr: 3.3356e-04  eta: 0:27:59  time: 15.3514   loss: 0.3545
11/08 02:03:48 - Epoch(train)  [33/100][5/8]  lr: 2.1841e-04  eta: 0:28:51  time: 16.0589   loss: 0.3107
11/08 02:04:06 - Epoch(train)  [34/100][5/8]  lr: 1.2208e-04  eta: 0:27:31  time: 15.5466   loss: 0.2687
11/08 02:04:23 - Epoch(train)  [35/100][5/8]  lr: 5.0999e-05  eta: 0:26:28  time: 15.1872   loss: 0.2844

11/08 02:04:26 - Epoch(test) - all: [35/100]:
Threshold is drived from OTSU algorithm.
11/08 02:04:51 - Epoch(test) : [5/16]
11/08 02:04:59 - Epoch(test) : [10/16]
11/08 02:05:05 - Epoch(test) : [15/16]
Accuracy: 0.65、Precision: 0.32、Recall: 0.79、F1-score: 0.45、Average_Precision: 0.70

11/08 02:05:07 - Epoch(test) - inshore: [35/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.72、Precision: 0.24、Recall: 0.62、F1-score: 0.35、Average_Precision: 0.35
11/08 02:05:37 - Epoch(train)  [36/100][5/8]  lr: 9.9062e-06  eta: 0:27:19  time: 15.9173   loss: 0.2264
11/08 02:05:56 - Epoch(train)  [37/100][5/8]  lr: 9.9895e-04  eta: 0:27:15  time: 16.1293   loss: 0.2002
11/08 02:06:14 - Epoch(train)  [38/100][5/8]  lr: 9.7402e-04  eta: 0:27:1  time: 16.2431   loss: 0.3325
11/08 02:06:32 - Epoch(train)  [39/100][5/8]  lr: 9.1746e-04  eta: 0:26:4  time: 15.9274   loss: 0.3072
11/08 02:06:50 - Epoch(train)  [40/100][5/8]  lr: 8.3304e-04  eta: 0:24:41  time: 15.3335   loss: 0.3030

11/08 02:06:52 - Epoch(test) - all: [40/100]:
Threshold is drived from OTSU algorithm.
11/08 02:07:19 - Epoch(test) : [5/16]
11/08 02:07:26 - Epoch(test) : [10/16]
11/08 02:07:32 - Epoch(test) : [15/16]
Accuracy: 0.50、Precision: 0.25、Recall: 0.88、F1-score: 0.39、Average_Precision: 0.70

11/08 02:07:34 - Epoch(test) - inshore: [40/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.53、Precision: 0.18、Recall: 0.81、F1-score: 0.29、Average_Precision: 0.33
11/08 02:08:06 - Epoch(train)  [41/100][5/8]  lr: 7.2641e-04  eta: 0:26:6  time: 16.4926   loss: 0.2743
11/08 02:08:25 - Epoch(train)  [42/100][5/8]  lr: 6.0468e-04  eta: 0:25:23  time: 16.3141   loss: 0.3355
11/08 02:08:43 - Epoch(train)  [43/100][5/8]  lr: 4.7598e-04  eta: 0:23:31  time: 15.3728   loss: 0.2135
11/08 02:09:02 - Epoch(train)  [44/100][5/8]  lr: 3.4890e-04  eta: 0:24:37  time: 16.3782   loss: 0.2982
11/08 02:09:21 - Epoch(train)  [45/100][5/8]  lr: 2.3192e-04  eta: 0:24:14  time: 16.4153   loss: 0.2343

11/08 02:09:23 - Epoch(test) - all: [45/100]:
Threshold is drived from OTSU algorithm.
11/08 02:09:48 - Epoch(test) : [5/16]
11/08 02:09:55 - Epoch(test) : [10/16]
11/08 02:10:02 - Epoch(test) : [15/16]
Accuracy: 0.47、Precision: 0.24、Recall: 0.92、F1-score: 0.39、Average_Precision: 0.71

11/08 02:10:03 - Epoch(test) - inshore: [45/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.49、Precision: 0.17、Recall: 0.86、F1-score: 0.29、Average_Precision: 0.34
11/08 02:10:32 - Epoch(train)  [46/100][5/8]  lr: 1.3286e-04  eta: 0:22:2  time: 15.2016   loss: 0.3021
11/08 02:10:51 - Epoch(train)  [47/100][5/8]  lr: 5.8323e-05  eta: 0:22:43  time: 15.9638   loss: 0.2599
11/08 02:11:09 - Epoch(train)  [48/100][5/8]  lr: 1.3288e-05  eta: 0:22:47  time: 16.3209   loss: 0.2628
11/08 02:11:27 - Epoch(train)  [49/100][5/8]  lr: 9.9974e-04  eta: 0:21:22  time: 15.5963   loss: 0.3128
11/08 02:11:45 - Epoch(train)  [50/100][5/8]  lr: 9.7892e-04  eta: 0:20:58  time: 15.6121   loss: 0.2154

11/08 02:11:48 - Epoch(test) - all: [50/100]:
Threshold is drived from OTSU algorithm.
11/08 02:12:15 - Epoch(test) : [5/16]
11/08 02:12:22 - Epoch(test) : [10/16]
11/08 02:12:29 - Epoch(test) : [15/16]
Accuracy: 0.66、Precision: 0.33、Recall: 0.84、F1-score: 0.47、Average_Precision: 0.72

11/08 02:12:31 - Epoch(test) - inshore: [50/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.72、Precision: 0.25、Recall: 0.70、F1-score: 0.37、Average_Precision: 0.35
11/08 02:13:04 - Epoch(train)  [51/100][5/8]  lr: 9.2615e-04  eta: 0:22:49  time: 17.3302   loss: 0.2502
11/08 02:13:24 - Epoch(train)  [52/100][5/8]  lr: 8.4494e-04  eta: 0:22:40  time: 17.5773   loss: 0.3359
11/08 02:13:43 - Epoch(train)  [53/100][5/8]  lr: 7.4072e-04  eta: 0:20:56  time: 16.5711   loss: 0.2811
11/08 02:14:04 - Epoch(train)  [54/100][5/8]  lr: 6.2045e-04  eta: 0:21:12  time: 17.1435   loss: 0.3472
11/08 02:14:23 - Epoch(train)  [55/100][5/8]  lr: 4.9216e-04  eta: 0:20:2  time: 16.5570   loss: 0.3064

11/08 02:14:27 - Epoch(test) - all: [55/100]:
Threshold is drived from OTSU algorithm.
11/08 02:14:54 - Epoch(test) : [5/16]
11/08 02:15:01 - Epoch(test) : [10/16]
11/08 02:15:07 - Epoch(test) : [15/16]
Accuracy: 0.29、Precision: 0.20、Recall: 0.96、F1-score: 0.33、Average_Precision: 0.70

11/08 02:15:10 - Epoch(test) - inshore: [55/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.27、Precision: 0.14、Recall: 0.95、F1-score: 0.24、Average_Precision: 0.36
11/08 02:15:40 - Epoch(train)  [56/100][5/8]  lr: 3.6440e-04  eta: 0:18:17  time: 15.4595   loss: 0.2387
11/08 02:15:57 - Epoch(train)  [57/100][5/8]  lr: 2.4572e-04  eta: 0:17:33  time: 15.1790   loss: 0.3192
11/08 02:16:17 - Epoch(train)  [58/100][5/8]  lr: 1.4402e-04  eta: 0:19:0  time: 16.8221   loss: 0.2429
11/08 02:16:36 - Epoch(train)  [59/100][5/8]  lr: 6.6111e-05  eta: 0:17:33  time: 15.9099   loss: 0.3370
11/08 02:16:54 - Epoch(train)  [60/100][5/8]  lr: 1.7181e-05  eta: 0:17:29  time: 16.2406   loss: 0.2697

11/08 02:16:56 - Epoch(test) - all: [60/100]:
Threshold is drived from OTSU algorithm.
11/08 02:17:23 - Epoch(test) : [5/16]
11/08 02:17:31 - Epoch(test) : [10/16]
11/08 02:17:37 - Epoch(test) : [15/16]
Accuracy: 0.27、Precision: 0.20、Recall: 0.97、F1-score: 0.33、Average_Precision: 0.71

11/08 02:17:39 - Epoch(test) - inshore: [60/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.19、Precision: 0.12、Recall: 0.94、F1-score: 0.22、Average_Precision: 0.37
11/08 02:18:09 - Epoch(train)  [61/100][5/8]  lr: 1.0000e-03  eta: 0:15:56  time: 15.1820   loss: 0.2246
11/08 02:18:28 - Epoch(train)  [62/100][5/8]  lr: 9.8332e-04  eta: 0:15:43  time: 15.3594   loss: 0.2408
11/08 02:18:47 - Epoch(train)  [63/100][5/8]  lr: 9.3439e-04  eta: 0:16:19  time: 16.3807   loss: 0.3501
11/08 02:19:05 - Epoch(train)  [64/100][5/8]  lr: 8.5648e-04  eta: 0:15:10  time: 15.6449   loss: 0.3613
11/08 02:19:23 - Epoch(train)  [65/100][5/8]  lr: 7.5478e-04  eta: 0:14:53  time: 15.7851   loss: 0.3441

11/08 02:19:25 - Epoch(test) - all: [65/100]:
Threshold is drived from OTSU algorithm.
11/08 02:19:51 - Epoch(test) : [5/16]
11/08 02:19:58 - Epoch(test) : [10/16]
11/08 02:20:04 - Epoch(test) : [15/16]
Accuracy: 0.27、Precision: 0.20、Recall: 0.99、F1-score: 0.33、Average_Precision: 0.64

11/08 02:20:05 - Epoch(test) - inshore: [65/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.27、Precision: 0.14、Recall: 0.95、F1-score: 0.24、Average_Precision: 0.34
11/08 02:20:35 - Epoch(train)  [66/100][5/8]  lr: 6.3610e-04  eta: 0:14:12  time: 15.5007   loss: 0.2911
11/08 02:20:54 - Epoch(train)  [67/100][5/8]  lr: 5.0834e-04  eta: 0:13:55  time: 15.6440   loss: 0.2791
11/08 02:21:12 - Epoch(train)  [68/100][5/8]  lr: 3.8005e-04  eta: 0:13:29  time: 15.6262   loss: 0.2926
11/08 02:21:30 - Epoch(train)  [69/100][5/8]  lr: 2.5978e-04  eta: 0:13:16  time: 15.8731   loss: 0.2386
11/08 02:21:48 - Epoch(train)  [70/100][5/8]  lr: 1.5556e-04  eta: 0:12:33  time: 15.5051   loss: 0.2686

11/08 02:21:50 - Epoch(test) - all: [70/100]:
Threshold is drived from OTSU algorithm.
11/08 02:22:18 - Epoch(test) : [5/16]
11/08 02:22:24 - Epoch(test) : [10/16]
11/08 02:22:31 - Epoch(test) : [15/16]
Accuracy: 0.19、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.73

11/08 02:22:33 - Epoch(test) - inshore: [70/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.39
11/08 02:23:04 - Epoch(train)  [71/100][5/8]  lr: 7.4355e-05  eta: 0:12:26  time: 15.8821   loss: 0.2267
11/08 02:23:23 - Epoch(train)  [72/100][5/8]  lr: 2.1581e-05  eta: 0:12:39  time: 16.7256   loss: 0.2684
11/08 02:23:41 - Epoch(train)  [73/100][5/8]  lr: 7.6208e-07  eta: 0:11:21  time: 15.5662   loss: 0.3156
11/08 02:23:59 - Epoch(train)  [74/100][5/8]  lr: 9.8721e-04  eta: 0:10:50  time: 15.4070   loss: 0.2732
11/08 02:24:17 - Epoch(train)  [75/100][5/8]  lr: 9.4218e-04  eta: 0:10:21  time: 15.3192   loss: 0.3604

11/08 02:24:20 - Epoch(test) - all: [75/100]:
Threshold is drived from OTSU algorithm.
11/08 02:24:47 - Epoch(test) : [5/16]
11/08 02:24:54 - Epoch(test) : [10/16]
11/08 02:24:59 - Epoch(test) : [15/16]
Accuracy: 0.19、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.68

11/08 02:25:01 - Epoch(test) - inshore: [75/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.13、Precision: 0.12、Recall: 1.00、F1-score: 0.22、Average_Precision: 0.34
11/08 02:25:36 - Epoch(train)  [76/100][5/8]  lr: 8.6764e-04  eta: 0:11:41  time: 17.9851   loss: 0.3089
11/08 02:25:55 - Epoch(train)  [77/100][5/8]  lr: 7.6858e-04  eta: 0:10:37  time: 17.0518   loss: 0.3429
11/08 02:26:15 - Epoch(train)  [78/100][5/8]  lr: 6.5160e-04  eta: 0:10:14  time: 17.1627   loss: 0.2873
11/08 02:26:35 - Epoch(train)  [79/100][5/8]  lr: 5.2452e-04  eta: 0:10:11  time: 17.8921   loss: 0.2266
11/08 02:26:55 - Epoch(train)  [80/100][5/8]  lr: 3.9582e-04  eta: 0:9:24  time: 17.3075   loss: 0.2164

11/08 02:26:58 - Epoch(test) - all: [80/100]:
Threshold is drived from OTSU algorithm.
11/08 02:27:27 - Epoch(test) : [5/16]
11/08 02:27:34 - Epoch(test) : [10/16]
11/08 02:27:40 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.75

11/08 02:27:42 - Epoch(test) - inshore: [80/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.41
11/08 02:28:17 - Epoch(train)  [81/100][5/8]  lr: 2.7409e-04  eta: 0:8:53  time: 17.2194   loss: 0.2132
11/08 02:28:37 - Epoch(train)  [82/100][5/8]  lr: 1.6746e-04  eta: 0:8:32  time: 17.4473   loss: 0.2782
11/08 02:28:57 - Epoch(train)  [83/100][5/8]  lr: 8.3045e-05  eta: 0:8:14  time: 17.8041   loss: 0.2914
11/08 02:29:17 - Epoch(train)  [84/100][5/8]  lr: 2.6482e-05  eta: 0:7:32  time: 17.2787   loss: 0.2645
11/08 02:29:37 - Epoch(train)  [85/100][5/8]  lr: 1.5481e-06  eta: 0:7:10  time: 17.4975   loss: 0.2671

11/08 02:29:40 - Epoch(test) - all: [85/100]:
Threshold is drived from OTSU algorithm.
11/08 02:30:13 - Epoch(test) : [5/16]
11/08 02:30:20 - Epoch(test) : [10/16]
11/08 02:30:27 - Epoch(test) : [15/16]
Accuracy: 0.19、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.75

11/08 02:30:29 - Epoch(test) - inshore: [85/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.41
11/08 02:31:07 - Epoch(train)  [86/100][5/8]  lr: 9.9059e-04  eta: 0:7:16  time: 18.9654   loss: 0.2589
11/08 02:31:29 - Epoch(train)  [87/100][5/8]  lr: 9.4950e-04  eta: 0:6:56  time: 19.4603   loss: 0.2739
11/08 02:31:52 - Epoch(train)  [88/100][5/8]  lr: 8.7842e-04  eta: 0:6:42  time: 20.3300   loss: 0.3333
11/08 02:32:14 - Epoch(train)  [89/100][5/8]  lr: 7.8209e-04  eta: 0:5:54  time: 19.4630   loss: 0.2274
11/08 02:32:38 - Epoch(train)  [90/100][5/8]  lr: 6.6694e-04  eta: 0:5:35  time: 20.1860   loss: 0.3065

11/08 02:32:41 - Epoch(test) - all: [90/100]:
Threshold is drived from OTSU algorithm.
11/08 02:33:14 - Epoch(test) : [5/16]
11/08 02:33:21 - Epoch(test) : [10/16]
11/08 02:33:27 - Epoch(test) : [15/16]
Accuracy: 0.19、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.69

11/08 02:33:30 - Epoch(test) - inshore: [90/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.37
11/08 02:34:06 - Epoch(train)  [91/100][5/8]  lr: 5.4067e-04  eta: 0:4:30  time: 18.0134   loss: 0.3359
11/08 02:34:28 - Epoch(train)  [92/100][5/8]  lr: 4.1170e-04  eta: 0:4:25  time: 19.7926   loss: 0.2798
11/08 02:34:52 - Epoch(train)  [93/100][5/8]  lr: 2.8864e-04  eta: 0:3:58  time: 20.1982   loss: 0.2696
11/08 02:35:13 - Epoch(train)  [94/100][5/8]  lr: 1.7971e-04  eta: 0:3:2  time: 17.8803   loss: 0.2899
11/08 02:35:38 - Epoch(train)  [95/100][5/8]  lr: 9.2172e-05  eta: 0:3:12  time: 22.3261   loss: 0.2797

11/08 02:35:41 - Epoch(test) - all: [95/100]:
Threshold is drived from OTSU algorithm.
11/08 02:36:15 - Epoch(test) : [5/16]
11/08 02:36:23 - Epoch(test) : [10/16]
11/08 02:36:30 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.71

11/08 02:36:32 - Epoch(test) - inshore: [95/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.37
11/08 02:37:10 - Epoch(train)  [96/100][5/8]  lr: 3.1881e-05  eta: 0:2:13  time: 19.0107   loss: 0.2721
11/08 02:37:33 - Epoch(train)  [97/100][5/8]  lr: 2.8571e-06  eta: 0:1:47  time: 19.9538   loss: 0.2600
11/08 02:37:55 - Epoch(train)  [98/100][5/8]  lr: 9.9346e-04  eta: 0:1:9  time: 18.2705   loss: 0.3314
11/08 02:38:19 - Epoch(train)  [99/100][5/8]  lr: 9.5635e-04  eta: 0:0:45  time: 20.4883   loss: 0.2893
11/08 02:38:42 - Epoch(train)  [100/100][5/8]  lr: 8.8880e-04  eta: 0:0:11  time: 19.4770   loss: 0.3137

11/08 02:38:46 - Epoch(test) - all: [100/100]:
Threshold is drived from OTSU algorithm.
11/08 02:39:17 - Epoch(test) : [5/16]
11/08 02:39:25 - Epoch(test) : [10/16]
11/08 02:39:34 - Epoch(test) : [15/16]
Accuracy: 0.18、Precision: 0.18、Recall: 1.00、F1-score: 0.31、Average_Precision: 0.71

11/08 02:39:36 - Epoch(test) - inshore: [100/100]:
Threshold is drived from OTSU algorithm.
Accuracy: 0.12、Precision: 0.12、Recall: 1.00、F1-score: 0.21、Average_Precision: 0.37
11/08 02:39:54 - Last model saved :work_dirs/SuperPoint+Boost-B_last_model_weight.pth
>>> model weights loaded from work_dirs/SuperPoint+Boost-B_25_best_model_weights_scratch_decay.pth with MD5 5d5e3dbcef545350f4b37f10caffbb64!

11/08 02:39:55 - Epoch(test) - all:
Threshold is drived from OTSU algorithm.
11/08 02:40:27 - Epoch(test) : [5/16]
11/08 02:40:37 - Epoch(test) : [10/16]
11/08 02:40:45 - Epoch(test) : [15/16]
Accuracy: 0.76、Precision: 0.42、Recall: 0.88、F1-score: 0.57、Average_Precision: 0.77

11/08 02:40:47 - Epoch(test) - offshore:
Threshold is drived from OTSU algorithm.
11/08 02:41:18 - Epoch(test) : [5/13]
11/08 02:41:24 - Epoch(test) : [10/13]
Accuracy: 0.94、Precision: 0.88、Recall: 0.97、F1-score: 0.92、Average_Precision: 0.95

11/08 02:41:31 - Epoch(test) - inshore:
Threshold is drived from OTSU algorithm.
Accuracy: 0.70、Precision: 0.26、Recall: 0.80、F1-score: 0.39、Average_Precision: 0.39
>>> PR_cruve saved: work_dirs/PR_curve_SuperPoint+Boost-B_25_best_model_weights_scratch_decay_5d5e3.png

